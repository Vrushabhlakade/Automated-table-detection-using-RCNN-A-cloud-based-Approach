{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9678d3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "#from pyimagesearch.nms import non_max_suppression\n",
    "#from pyimagesearch import config\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.models import load_model\n",
    "import numpy as np\n",
    "import argparse\n",
    "import imutils\n",
    "import pickle\n",
    "import cv2\n",
    "import pytesseract\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "afe40201",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_PROPOSALS = 2000\n",
    "MAX_PROPOSALS_INFER = 200\n",
    "INPUT_DIMS = (224, 224)\n",
    "MIN_PROBA = 0.99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ebf2959",
   "metadata": {},
   "outputs": [],
   "source": [
    "def non_max_suppression(boxes, probabilities, overlap_thresh):\n",
    "    if len(boxes) == 0:\n",
    "        return []\n",
    "\n",
    "    # Initialize the list of picked indexes\n",
    "    pick = []\n",
    "\n",
    "    # Grab the coordinates of the bounding boxes\n",
    "    x1 = boxes[:, 0]\n",
    "    y1 = boxes[:, 1]\n",
    "    x2 = boxes[:, 2]\n",
    "    y2 = boxes[:, 3]\n",
    "\n",
    "    # Compute the area of the bounding boxes and sort the bounding\n",
    "    # boxes by their probabilities\n",
    "    area = (x2 - x1 + 1) * (y2 - y1 + 1)\n",
    "    idxs = np.argsort(probabilities)\n",
    "\n",
    "    # Keep looping while some indexes still remain in the indexes list\n",
    "    while len(idxs) > 0:\n",
    "        # Grab the last index in the indexes list and add the index\n",
    "        # value to the list of picked indexes\n",
    "        last = len(idxs) - 1\n",
    "        i = idxs[last]\n",
    "        pick.append(i)\n",
    "\n",
    "        # Find the largest (x, y) coordinates for the start of the\n",
    "        # bounding box and the smallest (x, y) coordinates for the\n",
    "        # end of the bounding box\n",
    "        xx1 = np.maximum(x1[i], x1[idxs[:last]])\n",
    "        yy1 = np.maximum(y1[i], y1[idxs[:last]])\n",
    "        xx2 = np.minimum(x2[i], x2[idxs[:last]])\n",
    "        yy2 = np.minimum(y2[i], y2[idxs[:last]])\n",
    "\n",
    "        # Compute the width and height of the bounding box\n",
    "        w = np.maximum(0, xx2 - xx1 + 1)\n",
    "        h = np.maximum(0, yy2 - yy1 + 1)\n",
    "\n",
    "        # Compute the ratio of overlap\n",
    "        overlap = (w * h) / area[idxs[:last]]\n",
    "\n",
    "        # Delete all indexes from the index list that have overlap\n",
    "        # greater than the specified threshold\n",
    "        idxs = np.delete(idxs, np.concatenate(([last], np.where(overlap > overlap_thresh)[0])))\n",
    "\n",
    "    # Return only the bounding boxes and probabilities that were picked\n",
    "    return boxes[pick], probabilities[pick]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e8d8b14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH= r\"C:\\Users\\User\\Documents\\Table_Detection\\table_detector_RCNN_MobileNet.h5\"\n",
    "ENCODER_PATH= r\"C:\\Users\\User\\Documents\\Table_Detection\\label_encoder_RCNN_MobileNet.pickle\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "753ec253",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading model and label binarizer...\n",
      "[INFO] running selective search...\n",
      "[INFO] Number of proposals: 1072\n",
      "[INFO] proposals shape: (200, 224, 224, 3)\n",
      "[INFO] proposal shape: (200, 224, 224, 3)\n",
      "[INFO] classifying proposals...\n",
      "7/7 [==============================] - 4s 502ms/step\n",
      "[INFO] Available classes: ['no_table' 'table']\n",
      "[INFO] applying NMS...\n"
     ]
    }
   ],
   "source": [
    "# load the our fine-tuned model and label binarizer from disk\n",
    "print(\"[INFO] loading model and label binarizer...\")\n",
    "model = load_model(MODEL_PATH)\n",
    "lb = pickle.loads(open(ENCODER_PATH, \"rb\").read())\n",
    "# load the input image from disk\n",
    "image = cv2.imread(r\"E:\\TableBank2\\1-s2.0-S0168851017300386-mmc1_0.jpg\")\n",
    "image = imutils.resize(image, width=500)\n",
    "# run selective search on the image to generate bounding box proposal\n",
    "# regions\n",
    "print(\"[INFO] running selective search...\")\n",
    "ss = cv2.ximgproc.segmentation.createSelectiveSearchSegmentation()\n",
    "ss.setBaseImage(image)\n",
    "ss.switchToSelectiveSearchFast()\n",
    "rects = ss.process()\n",
    "print(\"[INFO] Number of proposals:\", len(rects))\n",
    "\n",
    "# initialize the list of region proposals that we'll be classifying\n",
    "# along with their associated bounding boxes\n",
    "proposals = []\n",
    "boxes = []\n",
    "# loop over the region proposal bounding box coordinates generated by\n",
    "# running selective search\n",
    "for (x, y, w, h) in rects[:MAX_PROPOSALS_INFER]:\n",
    "    # extract the region from the input image, convert it from BGR to\n",
    "    # RGB channel ordering, and then resize it to the required input\n",
    "    # dimensions of our trained CNN\n",
    "    roi = image[y:y + h, x:x + w]\n",
    "    roi = cv2.cvtColor(roi, cv2.COLOR_BGR2RGB)\n",
    "    roi = cv2.resize(roi, INPUT_DIMS,\n",
    "                     interpolation=cv2.INTER_CUBIC)\n",
    "    # further preprocess the ROI\n",
    "    roi = img_to_array(roi)\n",
    "    roi = preprocess_input(roi)\n",
    "    # update our proposals and bounding boxes lists\n",
    "    proposals.append(roi)\n",
    "    boxes.append((x, y, x + w, y + h))\n",
    "# convert the proposals and bounding boxes into NumPy arrays\n",
    "proposals = np.array(proposals, dtype=\"float32\")\n",
    "print(\"[INFO] proposals shape:\", proposals.shape)\n",
    "\n",
    "boxes = np.array(boxes, dtype=\"int32\")\n",
    "print(\"[INFO] proposal shape: {}\".format(proposals.shape))\n",
    "# classify each of the proposal ROIs using fine-tuned model\n",
    "print(\"[INFO] classifying proposals...\")\n",
    "proba = model.predict(proposals)\n",
    "print(\"[INFO] Available classes:\", lb.classes_)\n",
    "\n",
    "print(\"[INFO] applying NMS...\")\n",
    "labels = lb.classes_[np.argmax(proba, axis=1)]\n",
    "idxs = np.where(labels == \"table\")[0]\n",
    "# use the indexes to extract all bounding boxes and associated class\n",
    "# label probabilities associated with the \"raccoon\" class\n",
    "boxes = boxes[idxs]\n",
    "proba = proba[idxs][:, 1]\n",
    "# further filter indexes by enforcing a minimum prediction\n",
    "# probability be met\n",
    "idxs = np.where(proba >= MIN_PROBA)\n",
    "boxes = boxes[idxs]\n",
    "proba = proba[idxs]\n",
    "\n",
    "# clone the original image so that we can draw on it\n",
    "clone_after_nms = image.copy()\n",
    "clone_before_nms = image.copy()\n",
    "# loop over the bounding boxes and associated probabilities\n",
    "for (box, prob) in zip(boxes, proba):\n",
    "    # draw the bounding box, label, and probability on the image\n",
    "    (startX, startY, endX, endY) = box\n",
    "    cv2.rectangle(clone_before_nms, (startX, startY), (endX, endY),\n",
    "                  (0, 255, 0), 2)\n",
    "    y = startY - 10 if startY - 10 > 10 else startY + 10\n",
    "    text = \"table: {:.2f}%\".format(prob * 100)\n",
    "    cv2.putText(clone_before_nms, text, (startX, y),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.45, (0, 255, 0), 2)\n",
    "# show the output after *before* running NMS\n",
    "cv2.imshow(\"Before NMS\", clone_before_nms)\n",
    "\n",
    "# Apply non-maximum suppression\n",
    "overlap_thresh = 0.1  # Adjust this threshold as needed\n",
    "boxes_nms, proba_nms = non_max_suppression(boxes, proba, overlap_thresh)\n",
    "\n",
    "# Draw the remaining bounding boxes after NMS\n",
    "for (box, prob) in zip(boxes_nms, proba_nms):\n",
    "    # Draw the bounding box, label, and probability on the image\n",
    "    (startX, startY, endX, endY) = box\n",
    "    cv2.rectangle(clone_after_nms, (startX, startY), (endX, endY), (0, 255, 0), 2)\n",
    "    y = startY - 10 if startY - 10 > 10 else startY + 10\n",
    "    text = \"table: {:.2f}%\".format(prob * 100)\n",
    "    cv2.putText(clone_after_nms, text, (startX, y), cv2.FONT_HERSHEY_SIMPLEX, 0.45, (0, 255, 0), 2)\n",
    "\n",
    "cv2.imshow(\"After NMS\", clone_after_nms)\n",
    "\n",
    "\n",
    "# Wait for a key press and close all OpenCV windows\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "05748187",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pytesseract\n",
      "  Using cached pytesseract-0.3.10-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: Pillow>=8.0.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pytesseract) (9.4.0)\n",
      "Requirement already satisfied: packaging>=21.3 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pytesseract) (22.0)\n",
      "Installing collected packages: pytesseract\n",
      "Successfully installed pytesseract-0.3.10\n"
     ]
    }
   ],
   "source": [
    "!pip install pytesseract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c393b884",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading model and label binarizer...\n",
      "[INFO] running selective search...\n",
      "[INFO] Number of proposals: 1072\n",
      "[INFO] proposals shape: (200, 224, 224, 3)\n",
      "[INFO] proposal shape: (200, 224, 224, 3)\n",
      "[INFO] classifying proposals...\n",
      "7/7 [==============================] - 4s 518ms/step\n",
      "[INFO] Available classes: ['no_table' 'table']\n",
      "[INFO] applying NMS...\n",
      "Table 1 Extracted Data:\n",
      "['ond int website']\n",
      "\n",
      "\n",
      "Table 2 Extracted Data:\n",
      "['oer ae']\n",
      "\n",
      "\n",
      "Table 3 Extracted Data:\n",
      "['“Supplementary Table | Onkns forum with publications on the clalieod obesity araegy within 24 hows of', 'bin af he ty', 'aT RT', 'aaa']\n",
      "\n",
      "\n",
      "Table 4 Extracted Data:\n",
      "[]\n",
      "\n",
      "\n",
      "Table 5 Extracted Data:\n",
      "[]\n",
      "\n",
      "\n",
      "Table 6 Extracted Data:\n",
      "[]\n",
      "\n",
      "\n",
      "Table 7 Extracted Data:\n",
      "[]\n",
      "\n",
      "\n",
      "Table 8 Extracted Data:\n",
      "['“Supplementary Table | Online Toran wit pabcations on De allied oben aeay within 24 boas ot', 'bin af he ty', 'aT RT', 'aaa']\n",
      "\n",
      "\n",
      "Table 9 Extracted Data:\n",
      "['| pene ae Lene an ne', 'bln of he egy', 'ond int website', 'aaa']\n",
      "\n",
      "\n",
      "Table 10 Extracted Data:\n",
      "['Tie Pc ection whe UK goer sy on ido by in Engh uae ad', 'Sp TET Oak a wa POSS oS wT', 'bln of he egy', 'ond int website', 'aT RT', 'aaa']\n",
      "\n",
      "\n",
      "Table 11 Extracted Data:\n",
      "['Fond iat', 'ooo']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Load your fine-tuned model and label binarizer\n",
    "print(\"[INFO] loading model and label binarizer...\")\n",
    "model = load_model(MODEL_PATH)\n",
    "lb = pickle.loads(open(ENCODER_PATH, \"rb\").read())\n",
    "\n",
    "# Load the input image\n",
    "image = cv2.imread(r\"E:\\TableBank2\\1-s2.0-S0168851017300386-mmc1_0.jpg\")\n",
    "image = imutils.resize(image, width=500)\n",
    "\n",
    "# Run selective search to generate bounding box proposal regions\n",
    "print(\"[INFO] running selective search...\")\n",
    "ss = cv2.ximgproc.segmentation.createSelectiveSearchSegmentation()\n",
    "ss.setBaseImage(image)\n",
    "ss.switchToSelectiveSearchFast()\n",
    "rects = ss.process()\n",
    "print(\"[INFO] Number of proposals:\", len(rects))\n",
    "\n",
    "# Initialize the list of region proposals that we'll be classifying\n",
    "# along with their associated bounding boxes\n",
    "proposals = []\n",
    "boxes = []\n",
    "\n",
    "# Loop over the region proposal bounding box coordinates generated by\n",
    "# running selective search\n",
    "for (x, y, w, h) in rects[:MAX_PROPOSALS_INFER]:\n",
    "    # Extract the region from the input image, convert it from BGR to\n",
    "    # RGB channel ordering, and then resize it to the required input\n",
    "    # dimensions of our trained CNN\n",
    "    roi = image[y:y + h, x:x + w]\n",
    "    roi = cv2.cvtColor(roi, cv2.COLOR_BGR2RGB)\n",
    "    roi = cv2.resize(roi, INPUT_DIMS, interpolation=cv2.INTER_CUBIC)\n",
    "    # Further preprocess the ROI\n",
    "    roi = img_to_array(roi)\n",
    "    roi = preprocess_input(roi)\n",
    "    # Update our proposals and bounding boxes lists\n",
    "    proposals.append(roi)\n",
    "    boxes.append((x, y, x + w, y + h))\n",
    "\n",
    "# Convert the proposals and bounding boxes into NumPy arrays\n",
    "proposals = np.array(proposals, dtype=\"float32\")\n",
    "print(\"[INFO] proposals shape:\", proposals.shape)\n",
    "\n",
    "boxes = np.array(boxes, dtype=\"int32\")\n",
    "print(\"[INFO] proposal shape: {}\".format(proposals.shape))\n",
    "\n",
    "# Classify each of the proposal ROIs using the fine-tuned model\n",
    "print(\"[INFO] classifying proposals...\")\n",
    "proba = model.predict(proposals)\n",
    "print(\"[INFO] Available classes:\", lb.classes_)\n",
    "\n",
    "# Find the index of all predictions that are positive for the \"table\" class\n",
    "print(\"[INFO] applying NMS...\")\n",
    "labels = lb.classes_[np.argmax(proba, axis=1)]\n",
    "idxs = np.where(labels == \"table\")[0]\n",
    "\n",
    "# Use the indexes to extract all bounding boxes and associated class\n",
    "# label probabilities associated with the \"table\" class\n",
    "boxes = boxes[idxs]\n",
    "proba = proba[idxs][:, 1]\n",
    "\n",
    "# Further filter indexes by enforcing a minimum prediction\n",
    "# probability be met\n",
    "idxs = np.where(proba >= MIN_PROBA)\n",
    "boxes = boxes[idxs]\n",
    "proba = proba[idxs]\n",
    "\n",
    "# ... (previous code)\n",
    "\n",
    "# Clone the original image so that we can draw on it\n",
    "clone_after_nms = image.copy()\n",
    "\n",
    "# Function to enhance image quality\n",
    "def enhance_image(image):\n",
    "    # Convert the image to grayscale (assuming it's color)\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Apply histogram equalization to enhance contrast\n",
    "    equalized = cv2.equalizeHist(gray)\n",
    "    \n",
    "    # Apply Gaussian blur to reduce noise\n",
    "    blurred = cv2.GaussianBlur(equalized, (5, 5), 0)\n",
    "    \n",
    "    return blurred\n",
    "\n",
    "# Apply non-maximum suppression\n",
    "overlap_thresh = 0.1  # Adjust this threshold as needed\n",
    "boxes_nms, proba_nms = non_max_suppression(boxes, proba, overlap_thresh)\n",
    "\n",
    "# Initialize a list to store the extracted table images\n",
    "table_images = []\n",
    "\n",
    "# Loop over the bounding boxes and associated probabilities after NMS\n",
    "for (box, prob) in zip(boxes_nms, proba_nms):\n",
    "    # Extract the region corresponding to the table\n",
    "    (startX, startY, endX, endY) = box\n",
    "    table_roi = image[startY:endY, startX:endX]\n",
    "\n",
    "    # Enhance the quality of the table_roi\n",
    "    enhanced_table_roi = enhance_image(table_roi)\n",
    "\n",
    "    # Perform OCR on the enhanced table_roi to extract the table data\n",
    "    extracted_data = pytesseract.image_to_string(enhanced_table_roi)\n",
    "\n",
    "    # Append the extracted data to the list (or save the image if needed)\n",
    "    table_images.append(enhanced_table_roi)\n",
    "\n",
    "# Optionally, you can display or save the extracted and enhanced table images\n",
    "for i, table_image in enumerate(table_images):\n",
    "    cv2.imshow(f\"Table {i + 1}\", table_image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Optionally, you can also save the extracted and enhanced table images to files\n",
    "for i, table_image in enumerate(table_images):\n",
    "    cv2.imwrite(f\"table_{i + 1}.jpg\", table_image)\n",
    "\n",
    "# Optionally, you can perform further text processing or analysis on the extracted data\n",
    "for i, extracted_data in enumerate(table_data):\n",
    "    print(f\"Table {i + 1} Extracted Data:\")\n",
    "    print(extracted_data)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9ec4ae67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading model and label binarizer...\n",
      "[INFO] running selective search...\n",
      "[INFO] Number of proposals: 1614\n",
      "[INFO] proposals shape: (200, 224, 224, 3)\n",
      "[INFO] proposal shape: (200, 224, 224, 3)\n",
      "[INFO] classifying proposals...\n",
      "7/7 [==============================] - 4s 473ms/step\n",
      "[INFO] Available classes: ['no_table' 'table']\n",
      "[INFO] applying NMS...\n"
     ]
    }
   ],
   "source": [
    "# load the our fine-tuned model and label binarizer from disk\n",
    "print(\"[INFO] loading model and label binarizer...\")\n",
    "model = load_model(MODEL_PATH)\n",
    "lb = pickle.loads(open(ENCODER_PATH, \"rb\").read())\n",
    "# load the input image from disk\n",
    "image = cv2.imread(r\"E:\\TableBank\\Detection\\images\\%5BMS-GPOL%5D-170601_73.jpg\")\n",
    "image = imutils.resize(image, width=500)\n",
    "# run selective search on the image to generate bounding box proposal\n",
    "# regions\n",
    "print(\"[INFO] running selective search...\")\n",
    "ss = cv2.ximgproc.segmentation.createSelectiveSearchSegmentation()\n",
    "ss.setBaseImage(image)\n",
    "ss.switchToSelectiveSearchFast()\n",
    "rects = ss.process()\n",
    "print(\"[INFO] Number of proposals:\", len(rects))\n",
    "\n",
    "# initialize the list of region proposals that we'll be classifying\n",
    "# along with their associated bounding boxes\n",
    "proposals = []\n",
    "boxes = []\n",
    "# loop over the region proposal bounding box coordinates generated by\n",
    "# running selective search\n",
    "for (x, y, w, h) in rects[:MAX_PROPOSALS_INFER]:\n",
    "    # extract the region from the input image, convert it from BGR to\n",
    "    # RGB channel ordering, and then resize it to the required input\n",
    "    # dimensions of our trained CNN\n",
    "    roi = image[y:y + h, x:x + w]\n",
    "    roi = cv2.cvtColor(roi, cv2.COLOR_BGR2RGB)\n",
    "    roi = cv2.resize(roi, INPUT_DIMS,\n",
    "                     interpolation=cv2.INTER_CUBIC)\n",
    "    # further preprocess the ROI\n",
    "    roi = img_to_array(roi)\n",
    "    roi = preprocess_input(roi)\n",
    "    # update our proposals and bounding boxes lists\n",
    "    proposals.append(roi)\n",
    "    boxes.append((x, y, x + w, y + h))\n",
    "# convert the proposals and bounding boxes into NumPy arrays\n",
    "proposals = np.array(proposals, dtype=\"float32\")\n",
    "print(\"[INFO] proposals shape:\", proposals.shape)\n",
    "\n",
    "boxes = np.array(boxes, dtype=\"int32\")\n",
    "print(\"[INFO] proposal shape: {}\".format(proposals.shape))\n",
    "# classify each of the proposal ROIs using fine-tuned model\n",
    "print(\"[INFO] classifying proposals...\")\n",
    "proba = model.predict(proposals)\n",
    "print(\"[INFO] Available classes:\", lb.classes_)\n",
    "# find the index of all predictions that are positive for the\n",
    "# \"raccoon\" class\n",
    "print(\"[INFO] applying NMS...\")\n",
    "labels = lb.classes_[np.argmax(proba, axis=1)]\n",
    "idxs = np.where(labels == \"table\")[0]\n",
    "# use the indexes to extract all bounding boxes and associated class\n",
    "# label probabilities associated with the \"raccoon\" class\n",
    "boxes = boxes[idxs]\n",
    "proba = proba[idxs][:, 1]\n",
    "# further filter indexes by enforcing a minimum prediction\n",
    "# probability be met\n",
    "idxs = np.where(proba >= MIN_PROBA)\n",
    "boxes = boxes[idxs]\n",
    "proba = proba[idxs]\n",
    "\n",
    "# clone the original image so that we can draw on it\n",
    "clone_after_nms = image.copy()\n",
    "clone_before_nms = image.copy()\n",
    "# loop over the bounding boxes and associated probabilities\n",
    "for (box, prob) in zip(boxes, proba):\n",
    "    # draw the bounding box, label, and probability on the image\n",
    "    (startX, startY, endX, endY) = box\n",
    "    cv2.rectangle(clone_before_nms, (startX, startY), (endX, endY),\n",
    "                  (0, 255, 0), 2)\n",
    "    y = startY - 10 if startY - 10 > 10 else startY + 10\n",
    "    text = \"table: {:.2f}%\".format(prob * 100)\n",
    "    cv2.putText(clone_before_nms, text, (startX, y),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.45, (0, 255, 0), 2)\n",
    "# show the output after *before* running NMS\n",
    "cv2.imshow(\"Before NMS\", clone_before_nms)\n",
    "\n",
    "# Apply non-maximum suppression\n",
    "overlap_thresh = 0.1  # Adjust this threshold as needed\n",
    "boxes_nms, proba_nms = non_max_suppression(boxes, proba, overlap_thresh)\n",
    "\n",
    "# Draw the remaining bounding boxes after NMS\n",
    "for (box, prob) in zip(boxes_nms, proba_nms):\n",
    "    # Draw the bounding box, label, and probability on the image\n",
    "    (startX, startY, endX, endY) = box\n",
    "    cv2.rectangle(clone_after_nms, (startX, startY), (endX, endY), (0, 255, 0), 2)\n",
    "    y = startY - 10 if startY - 10 > 10 else startY + 10\n",
    "    text = \"table: {:.2f}%\".format(prob * 100)\n",
    "    cv2.putText(clone_after_nms, text, (startX, y), cv2.FONT_HERSHEY_SIMPLEX, 0.45, (0, 255, 0), 2)\n",
    "\n",
    "cv2.imshow(\"After NMS\", clone_after_nms)\n",
    "\n",
    "\n",
    "# Wait for a key press and close all OpenCV windows\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f8c255",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
